ğŸ“‹ PRISM í”„ë¡œì íŠ¸ ë¶„ì„ ë° ê¸°ìˆ  íšŒì˜ë¡
ë¬¸ì„œ ë²„ì „: 1.0
íšŒì˜ ì¼ì: 2025-12-11
ì°¸ì„ì: Senior Developer (íšŒì˜ ì§„í–‰), System Architect, Backend Engineer, Database Engineer, AI/ML Engineer, DevOps Engineer, Frontend Engineer, Security Engineer
ì‘ì„±ì: Senior Development Team
ëª©ì°¨
í”„ë¡œì íŠ¸ ë¶„ì„
ê¸°ìˆ  íšŒì˜ ë‚´ìš©
ì¢…í•© ì œì•ˆì„œ
ì•¡ì…˜ ì•„ì´í…œ
1. í”„ë¡œì íŠ¸ ë¶„ì„
ğŸ¯ í”„ë¡œì íŠ¸ ëª©ì 
PRISMì€ ë©€í‹°ëª¨ë‹¬ RAG(Retrieval-Augmented Generation) í”Œë«í¼ì…ë‹ˆë‹¤.
í•µì‹¬ ê¸°ëŠ¥:
ì‚¬ìš©ìê°€ ë‹¤ì–‘í•œ í˜•ì‹ì˜ ë¬¸ì„œ(í…ìŠ¤íŠ¸, ì´ë¯¸ì§€ ë“±)ë¥¼ ì—…ë¡œë“œ
ë²¡í„° DBì— ì €ì¥ ë° ì¸ë±ì‹±
ì§ˆë¬¸ì— ëŒ€í•´ ê´€ë ¨ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ì—¬ LLMì´ ë‹µë³€ì„ ìƒì„±
ğŸ’¡ í•µì‹¬ íŠ¹ì§•
Zero Cost ìš´ì˜: ë¬´ë£Œ í‹°ì–´ë§Œ í™œìš© (Supabase, Render, Vercel)
Clean Architecture: ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ê³¼ ì¸í”„ë¼ ì™„ì „ ë¶„ë¦¬
TDD ì›ì¹™: í…ŒìŠ¤íŠ¸ ì£¼ë„ ê°œë°œ
Model Agnostic: ì—¬ëŸ¬ LLM ëª¨ë¸ ìŠ¤ìœ„ì¹­ ê°€ëŠ¥
ğŸ“Š í˜„ì¬ ê¸°ìˆ  ìŠ¤íƒ
ì˜ì—­
ê¸°ìˆ 
ë¹„ê³ 
Language
Python 3.11+
ë¹„ë™ê¸° ì²˜ë¦¬ ë° íƒ€ì… íŒíŠ¸
Backend
FastAPI
ê³ ì„±ëŠ¥ API ì„œë²„
Frontend
Next.js
React ê¸°ë°˜ í”„ë ˆì„ì›Œí¬
Database
Supabase (PostgreSQL + pgvector)
ë²¡í„° ê²€ìƒ‰ ì§€ì›
Deployment
Docker + Render
ì»¨í…Œì´ë„ˆ ê¸°ë°˜ ë°°í¬
LLM
User API Key
OpenAI, Anthropic ë“±
2. ê¸°ìˆ  íšŒì˜ ë‚´ìš©
2.1 System Architect - ì•„í‚¤í…ì²˜ ê°œì„  ì œì•ˆ
âœ… í˜„ì¬ ì„¤ê³„ì˜ ê°•ì 
Hexagonal Architecture ì ìš©ìœ¼ë¡œ í™•ì¥ì„± í™•ë³´
Port & Adapter íŒ¨í„´ìœ¼ë¡œ ì™¸ë¶€ ì˜ì¡´ì„± ê²©ë¦¬
ë©€í‹°ëª¨ë‹¬ íŒŒì´í”„ë¼ì¸ êµ¬ì¡°ê°€ ëª…í™•í•¨
ğŸ”§ ê°œì„  ì œì•ˆ
1. ì´ë²¤íŠ¸ ê¸°ë°˜ ì•„í‚¤í…ì²˜ ì¶”ê°€
ë¬¸ì„œ ì—…ë¡œë“œ â†’ íŒŒì‹± â†’ ì„ë² ë”© â†’ ì €ì¥ì„ ì´ë²¤íŠ¸ ì²´ì¸ìœ¼ë¡œ ì²˜ë¦¬
- ë¹„ë™ê¸° ì²˜ë¦¬ë¡œ ëŒ€ìš©ëŸ‰ íŒŒì¼ ì—…ë¡œë“œ ì‹œ ì‘ë‹µì„± ê°œì„ 
- Event Sourcing íŒ¨í„´ ì ìš© ê°€ëŠ¥
2. CQRS íŒ¨í„´ ì ìš©
Command Side (ì“°ê¸°):
  - ë¬¸ì„œ ì—…ë¡œë“œ
  - ë¬¸ì„œ ì‚­ì œ
  - ì„¤ì • ë³€ê²½

Query Side (ì½ê¸°):
  - ë¬¸ì„œ ê²€ìƒ‰
  - ì±„íŒ… ì¿¼ë¦¬
  - í†µê³„ ì¡°íšŒ

ì´ì : ì½ê¸°/ì“°ê¸° ìµœì í™” ë¶„ë¦¬, í™•ì¥ì„± í–¥ìƒ
3. ìºì‹± ë ˆì´ì–´ ì¶”ê°€
- ìì£¼ ê²€ìƒ‰ë˜ëŠ” ì¿¼ë¦¬ ì„ë² ë”© ìºì‹± (Redis ë¬´ë£Œ í‹°ì–´)
- LLM ì‘ë‹µ ìºì‹±ìœ¼ë¡œ API ë¹„ìš© ì ˆê°
- TTL ê¸°ë°˜ ìºì‹œ ë¬´íš¨í™” ì „ëµ
2.2 Backend Engineer - êµ¬í˜„ ê°œì„  ì œì•ˆ
âœ… í˜„ì¬ ìŠ¤íƒì˜ ì¥ì 
FastAPIì˜ ë¹„ë™ê¸° ì²˜ë¦¬ ëŠ¥ë ¥
Supabaseì˜ pgvector í†µí•©
ğŸ”§ ê°œì„  ì œì•ˆ
1. ë°°ì¹˜ ì²˜ë¦¬ ì‹œìŠ¤í…œ ì¶”ê°€
# Celery + Redisë¥¼ ì‚¬ìš©í•œ ë¹„ë™ê¸° ì‘ì—… í

from celery import Celery

app = Celery('prism', broker='redis://localhost:6379')

@app.task
def process_large_document(document_id: str):
    """
    ëŒ€ìš©ëŸ‰ ë¬¸ì„œì˜ ì²­í‚¹/ì„ë² ë”©ì„ ë°±ê·¸ë¼ìš´ë“œ ì²˜ë¦¬
    """
    # ë¬¸ì„œ íŒŒì‹±
    # ì²­í‚¹
    # ì„ë² ë”© ìƒì„±
    # DB ì €ì¥
    pass
2. Rate Limiting & Throttling
from slowapi import Limiter
from slowapi.util import get_remote_address

limiter = Limiter(key_func=get_remote_address)

@app.post("/api/v1/chat")
@limiter.limit("10/minute")  # ë¶„ë‹¹ 10íšŒ ì œí•œ
async def chat_endpoint():
    pass
3. Health Check & Monitoring
ì—”ë“œí¬ì¸íŠ¸ êµ¬ì¡°:

/health
â”œâ”€â”€ /db        # Supabase ì—°ê²° ìƒíƒœ
â”œâ”€â”€ /llm       # LLM API ê°€ìš©ì„±
â”œâ”€â”€ /storage   # ìŠ¤í† ë¦¬ì§€ ìƒíƒœ
â””â”€â”€ /cache     # Redis ìƒíƒœ
4. API Versioning ì „ëµ
/api/v1/*  - í˜„ì¬ ë²„ì „
/api/v2/*  - í–¥í›„ ë²„ì „
- í•˜ìœ„ í˜¸í™˜ì„± ìœ ì§€ êµ¬ì¡°
- Deprecation ì •ì±… ìˆ˜ë¦½
2.3 Database Engineer - ë°ì´í„° ê³„ì¸µ ê°œì„  ì œì•ˆ
âœ… í˜„ì¬ ì„¤ê³„ ê²€í† 
pgvector í™œìš©ì€ ì ì ˆí•¨
match_documents í•¨ìˆ˜ëŠ” ê¸°ë³¸ì ì¸ êµ¬ì¡°
ğŸ”§ ê°œì„  ì œì•ˆ
1. ì¸ë±ì‹± ì „ëµ ê°œì„ 
-- HNSW ì¸ë±ìŠ¤ë¡œ ëŒ€ê·œëª¨ ë²¡í„° ê²€ìƒ‰ ì„±ëŠ¥ í–¥ìƒ
CREATE INDEX ON documents 
USING hnsw (embedding vector_cosine_ops)
WITH (m = 16, ef_construction = 64);

-- ë©”íƒ€ë°ì´í„° ê²€ìƒ‰ìš© GIN ì¸ë±ìŠ¤
CREATE INDEX idx_metadata ON documents 
USING gin (metadata jsonb_path_ops);

-- ë³µí•© ì¸ë±ìŠ¤ (ìì£¼ í•¨ê»˜ ì¡°íšŒë˜ëŠ” ì»¬ëŸ¼)
CREATE INDEX idx_user_created ON documents(user_id, created_at DESC);
2. íŒŒí‹°ì…”ë‹ ì „ëµ
-- ë‚ ì§œë³„ íŒŒí‹°ì…”ë‹ìœ¼ë¡œ ì„±ëŠ¥ ê°œì„ 
CREATE TABLE documents (
    id bigserial,
    user_id uuid NOT NULL,
    created_at timestamp NOT NULL,
    content text,
    metadata jsonb,
    embedding vector(1536)
) PARTITION BY RANGE (created_at);

-- ì›”ë³„ íŒŒí‹°ì…˜ ìƒì„±
CREATE TABLE documents_2025_01 PARTITION OF documents
    FOR VALUES FROM ('2025-01-01') TO ('2025-02-01');

CREATE TABLE documents_2025_02 PARTITION OF documents
    FOR VALUES FROM ('2025-02-01') TO ('2025-03-01');
3. Hybrid Search ê°œì„ 
-- BM25 í’€í…ìŠ¤íŠ¸ ê²€ìƒ‰ + ë²¡í„° ê²€ìƒ‰ ì¡°í•©
CREATE INDEX idx_content_fts ON documents 
USING gin(to_tsvector('english', content));

-- Hybrid Search í•¨ìˆ˜
CREATE OR REPLACE FUNCTION hybrid_search(
    query_text text,
    query_embedding vector(1536),
    match_count int DEFAULT 10,
    vector_weight float DEFAULT 0.5
)
RETURNS TABLE (
    id bigint,
    content text,
    metadata jsonb,
    hybrid_score float
)
LANGUAGE plpgsql
AS $$
BEGIN
    RETURN QUERY
    WITH vector_search AS (
        SELECT 
            id,
            content,
            metadata,
            1 - (embedding <=> query_embedding) as vector_similarity
        FROM documents
        ORDER BY embedding <=> query_embedding
        LIMIT match_count * 2
    ),
    text_search AS (
        SELECT 
            id,
            content,
            metadata,
            ts_rank(to_tsvector('english', content), 
                    plainto_tsquery('english', query_text)) as text_rank
        FROM documents
        WHERE to_tsvector('english', content) @@ plainto_tsquery('english', query_text)
        ORDER BY text_rank DESC
        LIMIT match_count * 2
    )
    SELECT 
        COALESCE(v.id, t.id) as id,
        COALESCE(v.content, t.content) as content,
        COALESCE(v.metadata, t.metadata) as metadata,
        (COALESCE(v.vector_similarity, 0) * vector_weight + 
         COALESCE(t.text_rank, 0) * (1 - vector_weight)) as hybrid_score
    FROM vector_search v
    FULL OUTER JOIN text_search t ON v.id = t.id
    ORDER BY hybrid_score DESC
    LIMIT match_count;
END;
$$;
4. ë°ì´í„° ì•„ì¹´ì´ë¹™ ì •ì±…
-- 90ì¼ ì´ìƒ ë¯¸ì‚¬ìš© ë¬¸ì„œ ìë™ ì•„ì¹´ì´ë¹™
CREATE TABLE documents_archive (
    LIKE documents INCLUDING ALL
);

-- ì•„ì¹´ì´ë¹™ í”„ë¡œì‹œì €
CREATE OR REPLACE FUNCTION archive_old_documents()
RETURNS void AS $$
BEGIN
    -- 90ì¼ ì´ìƒ ë¯¸ì ‘ê·¼ ë¬¸ì„œë¥¼ ì•„ì¹´ì´ë¸Œë¡œ ì´ë™
    WITH to_archive AS (
        DELETE FROM documents
        WHERE last_accessed_at < NOW() - INTERVAL '90 days'
        RETURNING *
    )
    INSERT INTO documents_archive
    SELECT * FROM to_archive;
END;
$$ LANGUAGE plpgsql;

-- ë§¤ì¼ ìë™ ì‹¤í–‰ (pg_cron ì‚¬ìš©)
SELECT cron.schedule('archive-old-docs', '0 2 * * *', 
    'SELECT archive_old_documents()');
2.4 AI/ML Engineer - LLM ë° ì„ë² ë”© ê°œì„  ì œì•ˆ
âœ… í˜„ì¬ êµ¬ì¡°ì˜ ì¥ì 
Model Agnostic ì„¤ê³„
Strategy Pattern í™œìš©
ğŸ”§ ê°œì„  ì œì•ˆ
1. Embedding ì „ëµ ê³ ë„í™”
from abc import ABC, abstractmethod
from typing import List
import numpy as np

class EmbeddingStrategy(ABC):
    @abstractmethod
    def embed(self, texts: List[str]) -> np.ndarray:
        pass

class HybridEmbeddingStrategy(EmbeddingStrategy):
    """
    Dense + Sparse ì„ë² ë”© ê²°í•©
    """
    def __init__(self):
        self.dense_model = OpenAIEmbedding()  # text-embedding-3-large
        self.sparse_model = SPLADEEmbedding()  # SPLADE
    
    def embed(self, texts: List[str]) -> dict:
        dense_vectors = self.dense_model.embed(texts)
        sparse_vectors = self.sparse_model.embed(texts)
        
        return {
            'dense': dense_vectors,
            'sparse': sparse_vectors
        }
2. Reranking íŒŒì´í”„ë¼ì¸ ì¶”ê°€
class RAGPipeline:
    """
    í–¥ìƒëœ RAG íŒŒì´í”„ë¼ì¸
    """
    def __init__(self):
        self.retriever = VectorRetriever()
        self.reranker = CohereReranker()  # ë˜ëŠ” Cross-Encoder
        self.llm = LLMProvider()
    
    async def process_query(self, query: str) -> str:
        # 1ë‹¨ê³„: ë²¡í„° ê²€ìƒ‰ìœ¼ë¡œ ìƒìœ„ 100ê°œ ì¶”ì¶œ
        candidates = await self.retriever.search(query, top_k=100)
        
        # 2ë‹¨ê³„: Rerankerë¡œ ìƒìœ„ 10ê°œ ì„ ë³„
        relevant_docs = await self.reranker.rerank(
            query=query,
            documents=candidates,
            top_k=10
        )
        
        # 3ë‹¨ê³„: LLMì— ì»¨í…ìŠ¤íŠ¸ë¡œ ì œê³µ
        response = await self.llm.generate(
            query=query,
            context=relevant_docs
        )
        
        return response
3. ì²­í‚¹ ì „ëµ ê°œì„ 
class SmartChunker:
    """
    ì˜ë¯¸ ê¸°ë°˜ ìŠ¤ë§ˆíŠ¸ ì²­í‚¹
    """
    def __init__(self, strategy: str = 'semantic'):
        self.strategy = strategy
    
    def chunk_by_semantic(self, text: str, 
                         max_tokens: int = 512,
                         overlap: int = 50) -> List[str]:
        """
        ì˜ë¯¸ ë‹¨ìœ„ë¡œ ë¬¸ì„œ ë¶„í• 
        - ë¬¸ì¥ ì„ë² ë”© ìœ ì‚¬ë„ ê¸°ë°˜
        - ê¸‰ê²©í•œ ì£¼ì œ ë³€í™” ì§€ì ì—ì„œ ë¶„í• 
        """
        sentences = self._split_sentences(text)
        embeddings = self._embed_sentences(sentences)
        
        chunks = []
        current_chunk = []
        current_tokens = 0
        
        for i, (sent, emb) in enumerate(zip(sentences, embeddings)):
            # ì£¼ì œ ë³€í™” ê°ì§€
            if i > 0 and self._is_topic_shift(embeddings[i-1], emb):
                if current_chunk:
                    chunks.append(' '.join(current_chunk))
                    current_chunk = []
                    current_tokens = 0
            
            current_chunk.append(sent)
            current_tokens += self._count_tokens(sent)
            
            if current_tokens >= max_tokens:
                chunks.append(' '.join(current_chunk))
                # ì˜¤ë²„ë© ìœ ì§€
                current_chunk = current_chunk[-overlap:]
                current_tokens = sum(self._count_tokens(s) 
                                   for s in current_chunk)
        
        if current_chunk:
            chunks.append(' '.join(current_chunk))
        
        return chunks
    
    def chunk_by_document_type(self, text: str, 
                               doc_type: str) -> List[str]:
        """
        ë¬¸ì„œ íƒ€ì…ë³„ ìµœì  ì²­í‚¹
        """
        strategies = {
            'code': self._chunk_code,
            'table': self._chunk_table,
            'academic': self._chunk_academic,
            'general': self._chunk_general
        }
        
        chunker = strategies.get(doc_type, self._chunk_general)
        return chunker(text)
4. Prompt Engineering ì²´ê³„í™”
# prompts/templates.py

PROMPT_TEMPLATES = {
    'qa': """
Given the following context from documents, answer the question.

Context:
{context}

Question: {question}

Instructions:
- Answer based only on the provided context
- If the answer is not in the context, say "I don't have enough information"
- Cite the source document when possible
- Be concise but complete

Answer:
""",
    
    'summarization': """
Summarize the following document in {length} style:

Document:
{document}

Summary:
""",
    
    'multi_doc': """
You have access to multiple documents. Synthesize information across them.

Documents:
{documents}

Task: {task}

Synthesis:
"""
}

class PromptManager:
    """
    í”„ë¡¬í”„íŠ¸ ë²„ì „ ê´€ë¦¬ ë° A/B í…ŒìŠ¤íŠ¸
    """
    def __init__(self):
        self.templates = PROMPT_TEMPLATES
        self.version = "1.0"
    
    def get_prompt(self, template_name: str, **kwargs) -> str:
        template = self.templates[template_name]
        return template.format(**kwargs)
    
    def ab_test(self, template_a: str, template_b: str, 
                query: str) -> dict:
        """
        ë‘ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì˜ ì„±ëŠ¥ ë¹„êµ
        """
        # ì‹¤ì œ êµ¬í˜„ ì‹œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
        pass
5. ë©€í‹°ëª¨ë‹¬ ì²˜ë¦¬ ê°•í™”
class MultimodalProcessor:
    """
    ë‹¤ì–‘í•œ ëª¨ë‹¬ë¦¬í‹° ì²˜ë¦¬
    """
    def __init__(self):
        self.vision_model = GPT4Vision()
        self.audio_model = WhisperAPI()
        self.table_parser = UnstructuredIO()
    
    async def process_image(self, image_path: str) -> dict:
        """
        ì´ë¯¸ì§€ â†’ í…ìŠ¤íŠ¸ ì„¤ëª… + ì„ë² ë”©
        """
        # Vision LMìœ¼ë¡œ ìƒì„¸ ì„¤ëª… ìƒì„±
        description = await self.vision_model.describe(
            image_path,
            prompt="Describe this image in detail for search purposes"
        )
        
        # OCR í…ìŠ¤íŠ¸ ì¶”ì¶œ
        ocr_text = await self.vision_model.extract_text(image_path)
        
        return {
            'description': description,
            'ocr_text': ocr_text,
            'type': 'image'
        }
    
    async def process_audio(self, audio_path: str) -> dict:
        """
        ì˜¤ë””ì˜¤ â†’ í…ìŠ¤íŠ¸ ë³€í™˜
        """
        transcript = await self.audio_model.transcribe(audio_path)
        
        return {
            'transcript': transcript,
            'type': 'audio'
        }
    
    async def process_table(self, table_html: str) -> dict:
        """
        í…Œì´ë¸” â†’ êµ¬ì¡°í™”ëœ í…ìŠ¤íŠ¸
        """
        # Unstructured.ioë¡œ íŒŒì‹±
        structured_data = self.table_parser.parse_table(table_html)
        
        # LLMìœ¼ë¡œ ìì—°ì–´ ì„¤ëª… ìƒì„±
        description = await self.llm.describe_table(structured_data)
        
        return {
            'data': structured_data,
            'description': description,
            'type': 'table'
        }
2.5 DevOps Engineer - ë°°í¬ ë° ìš´ì˜ ê°œì„  ì œì•ˆ
âœ… í˜„ì¬ ê³„íš ê²€í† 
Docker + Render ì¡°í•©ì€ ì ì ˆ
ë¬´ë£Œ í‹°ì–´ í™œìš© ì „ëµ Good
ğŸ”§ ê°œì„  ì œì•ˆ
1. CI/CD íŒŒì´í”„ë¼ì¸ êµ¬ì¶•
# .github/workflows/deploy.yml

name: PRISM CI/CD Pipeline

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install pytest pytest-cov ruff black
      
      - name: Run tests with coverage
        run: |
          pytest tests/ --cov=src --cov-report=xml
      
      - name: Code quality check
        run: |
          ruff check src/
          black --check src/
      
      - name: Upload coverage
        uses: codecov/codecov-action@v3

  build:
    needs: test
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    
    steps:
      - uses: actions/checkout@v3
      
      - name: Build Docker image
        run: |
          docker build -t prism-backend:${{ github.sha }} .
      
      - name: Push to registry
        run: |
          echo ${{ secrets.DOCKER_PASSWORD }} | docker login -u ${{ secrets.DOCKER_USERNAME }} --password-stdin
          docker push prism-backend:${{ github.sha }}

  deploy:
    needs: build
    runs-on: ubuntu-latest
    
    steps:
      - name: Deploy to Render
        run: |
          curl -X POST ${{ secrets.RENDER_DEPLOY_HOOK }}
      
      - name: Health check
        run: |
          sleep 30
          curl -f https://prism-api.render.com/health || exit 1
      
      - name: Notify deployment
        uses: 8398a7/action-slack@v3
        with:
          status: ${{ job.status }}
          text: 'Deployment completed'
          webhook_url: ${{ secrets.SLACK_WEBHOOK }}
2. í™˜ê²½ ë¶„ë¦¬ ì „ëµ
í”„ë¡œì íŠ¸ êµ¬ì¡°:

prism/
â”œâ”€â”€ environments/
â”‚   â”œâ”€â”€ dev/
â”‚   â”‚   â”œâ”€â”€ .env.dev
â”‚   â”‚   â””â”€â”€ docker-compose.dev.yml
â”‚   â”œâ”€â”€ staging/
â”‚   â”‚   â”œâ”€â”€ .env.staging
â”‚   â”‚   â””â”€â”€ docker-compose.staging.yml
â”‚   â””â”€â”€ production/
â”‚       â”œâ”€â”€ .env.production
â”‚       â””â”€â”€ docker-compose.prod.yml
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ Dockerfile.dev
â”‚   â””â”€â”€ Dockerfile.prod
â””â”€â”€ scripts/
    â”œâ”€â”€ deploy-dev.sh
    â”œâ”€â”€ deploy-staging.sh
    â””â”€â”€ deploy-prod.sh
3. ëª¨ë‹ˆí„°ë§ ìŠ¤íƒ (ë¬´ë£Œ í‹°ì–´ í™œìš©)
# monitoring/setup.py

import sentry_sdk
from sentry_sdk.integrations.fastapi import FastApiIntegration
from prometheus_client import Counter, Histogram

# Sentry ì„¤ì • (ì—ëŸ¬ íŠ¸ë˜í‚¹)
sentry_sdk.init(
    dsn=os.getenv("SENTRY_DSN"),
    integrations=[FastApiIntegration()],
    traces_sample_rate=0.1,
    environment=os.getenv("APP_ENV")
)

# Prometheus ë©”íŠ¸ë¦­
request_count = Counter(
    'prism_requests_total',
    'Total request count',
    ['method', 'endpoint', 'status']
)

request_duration = Histogram(
    'prism_request_duration_seconds',
    'Request duration',
    ['method', 'endpoint']
)

llm_token_usage = Counter(
    'prism_llm_tokens_total',
    'Total LLM tokens used',
    ['model', 'operation']
)

# ëª¨ë‹ˆí„°ë§ ë„êµ¬ ëª©ë¡:
# - Sentry (ë¬´ë£Œ í‹°ì–´): ì—ëŸ¬ íŠ¸ë˜í‚¹, ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
# - Uptime Robot (ë¬´ë£Œ): ê°€ë™ ì‹œê°„ ëª¨ë‹ˆí„°ë§
# - Grafana Cloud (ë¬´ë£Œ): ë©”íŠ¸ë¦­ ì‹œê°í™”
# - Better Stack (ë¬´ë£Œ í‹°ì–´): ë¡œê·¸ ì§‘ê³„
4. ë°±ì—… ì „ëµ
#!/bin/bash
# scripts/backup.sh

# Supabase ë°ì´í„° ë°±ì—… ìŠ¤í¬ë¦½íŠ¸

DATE=$(date +%Y%m%d_%H%M%S)
BACKUP_DIR="backups/$DATE"

echo "Starting backup at $DATE"

# 1. PostgreSQL ë°ì´í„° ë°±ì—…
pg_dump "$SUPABASE_DB_URL" > "$BACKUP_DIR/database.sql"

# 2. ë²¡í„° ë°ì´í„° ë³„ë„ ë°±ì—… (ëŒ€ìš©ëŸ‰ì¼ ê²½ìš°)
psql "$SUPABASE_DB_URL" -c "COPY documents TO STDOUT" | gzip > "$BACKUP_DIR/vectors.csv.gz"

# 3. ë©”íƒ€ë°ì´í„°ë§Œ ë°±ì—… (ë¹ ë¥¸ ë³µêµ¬ìš©)
psql "$SUPABASE_DB_URL" -c "SELECT id, metadata FROM documents" > "$BACKUP_DIR/metadata.json"

# 4. Backblaze B2ì— ì—…ë¡œë“œ (ë¬´ë£Œ í‹°ì–´ 10GB)
b2 sync "$BACKUP_DIR" "b2://prism-backups/$DATE"

# 5. 30ì¼ ì´ìƒ ëœ ë°±ì—… ì‚­ì œ
find backups/ -type d -mtime +30 -exec rm -rf {} \;

echo "Backup completed"
5. Zero-Downtime ë°°í¬
# docker-compose.prod.yml

version: '3.8'

services:
  prism-blue:
    image: prism-backend:latest
    environment:
      - DEPLOYMENT_SLOT=blue
    ports:
      - "8000:8000"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 10s
      timeout: 5s
      retries: 3

  prism-green:
    image: prism-backend:${NEW_VERSION}
    environment:
      - DEPLOYMENT_SLOT=green
    ports:
      - "8001:8000"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 10s
      timeout: 5s
      retries: 3

  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
    depends_on:
      - prism-blue
      - prism-green
#!/bin/bash
# scripts/blue-green-deploy.sh

# Blue-Green Deployment ìŠ¤í¬ë¦½íŠ¸

CURRENT_SLOT=$(curl -s http://localhost/health | jq -r '.slot')

if [ "$CURRENT_SLOT" == "blue" ]; then
    NEW_SLOT="green"
    NEW_PORT=8001
else
    NEW_SLOT="blue"
    NEW_PORT=8000
fi

echo "Current slot: $CURRENT_SLOT, Deploying to: $NEW_SLOT"

# 1. ìƒˆ ë²„ì „ ë°°í¬
docker-compose up -d prism-$NEW_SLOT

# 2. Health check ëŒ€ê¸°
for i in {1..30}; do
    if curl -f http://localhost:$NEW_PORT/health; then
        echo "New deployment is healthy"
        break
    fi
    sleep 2
done

# 3. íŠ¸ë˜í”½ ì „í™˜
nginx -s reload

# 4. ì´ì „ ë²„ì „ ì¢…ë£Œ
sleep 10
docker-compose stop prism-$CURRENT_SLOT

echo "Deployment completed. Active slot: $NEW_SLOT"
2.6 Frontend Engineer - UI/UX ê°œì„  ì œì•ˆ
âœ… í˜„ì¬ ê³„íš
Next.js ì„ íƒì€ ì ì ˆí•¨
Vercel ë°°í¬ ì „ëµ Good
ğŸ”§ ê°œì„  ì œì•ˆ
1. UI/UX ì»´í¬ë„ŒíŠ¸ ì²´ê³„
// components/upload/DragDropZone.tsx

import { useDropzone } from 'react-dropzone';
import { useState } from 'react';

interface FileWithPreview extends File {
  preview: string;
}

export function DragDropZone({ onUpload }: { onUpload: (files: File[]) => void }) {
  const [files, setFiles] = useState<FileWithPreview[]>([]);

  const { getRootProps, getInputProps, isDragActive } = useDropzone({
    accept: {
      'application/pdf': ['.pdf'],
      'text/plain': ['.txt'],
      'application/msword': ['.doc', '.docx'],
      'image/*': ['.png', '.jpg', '.jpeg']
    },
    maxSize: 10 * 1024 * 1024, // 10MB
    onDrop: (acceptedFiles) => {
      const filesWithPreview = acceptedFiles.map(file =>
        Object.assign(file, {
          preview: URL.createObjectURL(file)
        })
      );
      setFiles(filesWithPreview);
      onUpload(acceptedFiles);
    }
  });

  return (
    <div
      {...getRootProps()}
      className={`border-2 border-dashed rounded-lg p-8 text-center transition-colors
        ${isDragActive ? 'border-blue-500 bg-blue-50' : 'border-gray-300 hover:border-gray-400'}`}
    >
      <input {...getInputProps()} />
      <div className="space-y-4">
        <UploadIcon className="mx-auto h-12 w-12 text-gray-400" />
        {isDragActive ? (
          <p>Drop files here...</p>
        ) : (
          <p>Drag & drop files here, or click to select</p>
        )}
        <p className="text-sm text-gray-500">
          Supports: PDF, TXT, DOCX, Images (max 10MB)
        </p>
      </div>
      
      {files.length > 0 && (
        <div className="mt-4 grid grid-cols-3 gap-4">
          {files.map((file, idx) => (
            <FilePreview key={idx} file={file} />
          ))}
        </div>
      )}
    </div>
  );
}
// components/chat/MessageList.tsx

import { useVirtualizer } from '@tanstack/react-virtual';
import { useRef } from 'react';

interface Message {
  id: string;
  role: 'user' | 'assistant';
  content: string;
  sources?: Source[];
  timestamp: Date;
}

export function MessageList({ messages }: { messages: Message[] }) {
  const parentRef = useRef<HTMLDivElement>(null);

  const virtualizer = useVirtualizer({
    count: messages.length,
    getScrollElement: () => parentRef.current,
    estimateSize: () => 100,
    overscan: 5
  });

  return (
    <div ref={parentRef} className="h-full overflow-auto">
      <div
        style={{
          height: `${virtualizer.getTotalSize()}px`,
          position: 'relative'
        }}
      >
        {virtualizer.getVirtualItems().map((virtualRow) => {
          const message = messages[virtualRow.index];
          return (
            <div
              key={message.id}
              style={{
                position: 'absolute',
                top: 0,
                left: 0,
                width: '100%',
                transform: `translateY(${virtualRow.start}px)`
              }}
            >
              <MessageBubble message={message} />
            </div>
          );
        })}
      </div>
    </div>
  );
}
// components/chat/SourceCard.tsx

interface Source {
  id: string;
  title: string;
  snippet: string;
  similarity: number;
}

export function SourceCard({ sources }: { sources: Source[] }) {
  return (
    <div className="mt-4 space-y-2">
      <p className="text-sm font-medium text-gray-700">Sources:</p>
      <div className="grid gap-2">
        {sources.map((source) => (
          <div
            key={source.id}
            className="border rounded-lg p-3 hover:bg-gray-50 cursor-pointer"
          >
            <div className="flex justify-between items-start">
              <h4 className="font-medium text-sm">{source.title}</h4>
              <span className="text-xs text-gray-500">
                {(source.similarity * 100).toFixed(0)}% match
              </span>
            </div>
            <p className="text-sm text-gray-600 mt-1 line-clamp-2">
              {source.snippet}
            </p>
          </div>
        ))}
      </div>
    </div>
  );
}
2. ì‹¤ì‹œê°„ ê¸°ëŠ¥
// hooks/useStreamingChat.ts

import { useState, useCallback } from 'react';

export function useStreamingChat() {
  const [isStreaming, setIsStreaming] = useState(false);
  const [streamedContent, setStreamedContent] = useState('');

  const sendMessage = useCallback(async (message: string) => {
    setIsStreaming(true);
    setStreamedContent('');

    const response = await fetch('/api/v1/chat/stream', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ message })
    });

    const reader = response.body?.getReader();
    const decoder = new TextDecoder();

    while (true) {
      const { done, value } = await reader!.read();
      if (done) break;

      const chunk = decoder.decode(value);
      const lines = chunk.split('\n');

      for (const line of lines) {
        if (line.startsWith('data: ')) {
          const data = JSON.parse(line.slice(6));
          setStreamedContent(prev => prev + data.content);
        }
      }
    }

    setIsStreaming(false);
  }, []);

  return { sendMessage, isStreaming, streamedContent };
}
// hooks/useUploadProgress.ts

import { useState } from 'react';

export function useUploadProgress() {
  const [progress, setProgress] = useState(0);
  const [status, setStatus] = useState<'idle' | 'uploading' | 'processing' | 'complete'>('idle');

  const uploadFile = async (file: File) => {
    setStatus('uploading');
    
    // Server-Sent Eventsë¡œ ì§„í–‰ë¥  ìˆ˜ì‹ 
    const eventSource = new EventSource('/api/v1/upload/progress');
    
    eventSource.onmessage = (event) => {
      const data = JSON.parse(event.data);
      setProgress(data.progress);
      setStatus(data.status);
      
      if (data.status === 'complete') {
        eventSource.close();
      }
    };

    // íŒŒì¼ ì—…ë¡œë“œ
    const formData = new FormData();
    formData.append('file', file);

    await fetch('/api/v1/upload', {
      method: 'POST',
      body: formData
    });
  };

  return { uploadFile, progress, status };
}
3. ì„±ëŠ¥ ìµœì í™”
// lib/api-client.ts

import { QueryClient } from '@tanstack/react-query';

export const queryClient = new QueryClient({
  defaultOptions: {
    queries: {
      staleTime: 5 * 60 * 1000, // 5ë¶„
      cacheTime: 10 * 60 * 1000, // 10ë¶„
      refetchOnWindowFocus: false,
      retry: 1
    }
  }
});

// API í•¨ìˆ˜ë“¤
export const api = {
  chat: {
    send: async (message: string) => {
      const response = await fetch('/api/v1/chat', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ message })
      });
      return response.json();
    }
  },
  
  documents: {
    list: async () => {
      const response = await fetch('/api/v1/documents');
      return response.json();
    },
    
    upload: async (file: File) => {
      const formData = new FormData();
      formData.append('file', file);
      const response = await fetch('/api/v1/documents', {
        method: 'POST',
        body: formData
      });
      return response.json();
    }
  }
};
// next.config.js

module.exports = {
  // ì´ë¯¸ì§€ ìµœì í™”
  images: {
    domains: ['your-supabase-project.supabase.co'],
    formats: ['image/avif', 'image/webp']
  },
  
  // ì½”ë“œ ìŠ¤í”Œë¦¬íŒ…
  experimental: {
    optimizeCss: true
  },
  
  // ë²ˆë“¤ ë¶„ì„
  webpack: (config, { isServer }) => {
    if (!isServer) {
      config.optimization.splitChunks = {
        chunks: 'all',
        cacheGroups: {
          default: false,
          vendors: false,
          commons: {
            name: 'commons',
            chunks: 'all',
            minChunks: 2
          }
        }
      };
    }
    return config;
  }
};
4. ì ‘ê·¼ì„± (a11y)
// components/common/AccessibleButton.tsx

import { forwardRef } from 'react';

interface ButtonProps extends React.ButtonHTMLAttributes<HTMLButtonElement> {
  loading?: boolean;
  ariaLabel?: string;
}

export const AccessibleButton = forwardRef<HTMLButtonElement, ButtonProps>(
  ({ loading, ariaLabel, children, ...props }, ref) => {
    return (
      <button
        ref={ref}
        aria-label={ariaLabel}
        aria-busy={loading}
        aria-disabled={props.disabled || loading}
        {...props}
      >
        {loading ? (
          <>
            <span className="sr-only">Loading...</span>
            <LoadingSpinner />
          </>
        ) : (
          children
        )}
      </button>
    );
  }
);
// components/common/SkipLink.tsx

export function SkipLink() {
  return (
    <a
      href="#main-content"
      className="sr-only focus:not-sr-only focus:absolute focus:top-4 focus:left-4 
                 focus:z-50 focus:px-4 focus:py-2 focus:bg-blue-600 focus:text-white"
    >
      Skip to main content
    </a>
  );
}
5. ìƒíƒœ ê´€ë¦¬ ì „ëµ
// store/chatStore.ts

import create from 'zustand';
import { persist } from 'zustand/middleware';

interface ChatState {
  messages: Message[];
  currentSession: string | null;
  addMessage: (message: Message) => void;
  clearMessages: () => void;
  setSession: (sessionId: string) => void;
}

export const useChatStore = create<ChatState>()(
  persist(
    (set) => ({
      messages: [],
      currentSession: null,
      
      addMessage: (message) =>
        set((state) => ({
          messages: [...state.messages, message]
        })),
      
      clearMessages: () => set({ messages: [] }),
      
      setSession: (sessionId) => set({ currentSession: sessionId })
    }),
    {
      name: 'chat-storage',
      partialize: (state) => ({ messages: state.messages })
    }
  )
);
// contexts/ThemeContext.tsx

import { createContext, useContext, useEffect, useState } from 'react';

type Theme = 'light' | 'dark' | 'system';

const ThemeContext = createContext<{
  theme: Theme;
  setTheme: (theme: Theme) => void;
}>({
  theme: 'system',
  setTheme: () => {}
});

export function ThemeProvider({ children }: { children: React.ReactNode }) {
  const [theme, setTheme] = useState<Theme>('system');

  useEffect(() => {
    const root = window.document.documentElement;
    root.classList.remove('light', 'dark');

    if (theme === 'system') {
      const systemTheme = window.matchMedia('(prefers-color-scheme: dark)').matches
        ? 'dark'
        : 'light';
      root.classList.add(systemTheme);
    } else {
      root.classList.add(theme);
    }
  }, [theme]);

  return (
    <ThemeContext.Provider value={{ theme, setTheme }}>
      {children}
    </ThemeContext.Provider>
  );
}

export const useTheme = () => useContext(ThemeContext);
2.7 Security Engineer - ë³´ì•ˆ ê°•í™” ì œì•ˆ
âœ… ë³´ì•ˆ ê´€ì  ë¶„ì„
í˜„ì¬ ì„¤ê³„ì— ì¸ì¦/ì¸ê°€ ì²´ê³„ê°€ ëª…ì‹œë˜ì§€ ì•ŠìŒ
API Key ê´€ë¦¬ ë°©ì•ˆ í•„ìš”
íŒŒì¼ ì—…ë¡œë“œ ë³´ì•ˆ ê²€ì¦ í•„ìš”
ğŸ”§ ë³´ì•ˆ ê°œì„  ì œì•ˆ
1. ì¸ì¦/ì¸ê°€ ì²´ê³„
# infrastructure/auth/supabase_auth.py

from supabase import Client
from fastapi import HTTPException, Security
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from typing import Optional
import jwt

security = HTTPBearer()

class AuthService:
    def __init__(self, supabase: Client):
        self.supabase = supabase
    
    async def verify_token(
        self,
        credentials: HTTPAuthorizationCredentials = Security(security)
    ) -> dict:
        """
        JWT í† í° ê²€ì¦
        """
        try:
            token = credentials.credentials
            user = self.supabase.auth.get_user(token)
            
            if not user:
                raise HTTPException(status_code=401, detail="Invalid token")
            
            return user
        except Exception as e:
            raise HTTPException(status_code=401, detail=str(e))
    
    async def check_permission(
        self,
        user_id: str,
        resource: str,
        action: str
    ) -> bool:
        """
        ê¶Œí•œ í™•ì¸ (RBAC)
        """
        # Supabaseì—ì„œ ì‚¬ìš©ì ì—­í•  ì¡°íšŒ
        response = self.supabase.table('user_roles').select('*').eq(
            'user_id', user_id
        ).execute()
        
        roles = [r['role'] for r in response.data]
        
        # ê¶Œí•œ ë§¤íŠ¸ë¦­ìŠ¤ í™•ì¸
        permissions = {
            'admin': ['*'],
            'user': ['document:read', 'document:create', 'document:delete:own'],
            'guest': ['document:read']
        }
        
        for role in roles:
            if action in permissions.get(role, []) or '*' in permissions.get(role, []):
                return True
        
        return False
# presentation/api/dependencies.py

from fastapi import Depends, HTTPException
from infrastructure.auth.supabase_auth import AuthService

async def get_current_user(
    auth_service: AuthService = Depends()
) -> dict:
    """
    í˜„ì¬ ë¡œê·¸ì¸í•œ ì‚¬ìš©ì ì •ë³´ ë°˜í™˜
    """
    user = await auth_service.verify_token()
    return user

async def require_permission(resource: str, action: str):
    """
    íŠ¹ì • ê¶Œí•œ ìš”êµ¬
    """
    async def permission_checker(
        user: dict = Depends(get_current_user),
        auth_service: AuthService = Depends()
    ):
        has_permission = await auth_service.check_permission(
            user['id'], resource, action
        )
        
        if not has_permission:
            raise HTTPException(status_code=403, detail="Permission denied")
        
        return user
    
    return permission_checker
2. API Key ë³´ì•ˆ ê´€ë¦¬
# infrastructure/secrets/key_manager.py

import os
from typing import Optional
from cryptography.fernet import Fernet
import hashlib

class KeyManager:
    """
    API Key ì•”í˜¸í™” ë° ê´€ë¦¬
    """
    def __init__(self):
        # í™˜ê²½ë³€ìˆ˜ì—ì„œ ë§ˆìŠ¤í„° í‚¤ ë¡œë“œ
        master_key = os.getenv('MASTER_ENCRYPTION_KEY')
        if not master_key:
            raise ValueError("MASTER_ENCRYPTION_KEY not set")
        
        # Fernet ì•”í˜¸í™” í‚¤ ìƒì„±
        key_hash = hashlib.sha256(master_key.encode()).digest()
        self.cipher = Fernet(key_hash[:32])
    
    def encrypt_key(self, api_key: str) -> str:
        """
        API Key ì•”í˜¸í™”
        """
        encrypted = self.cipher.encrypt(api_key.encode())
        return encrypted.decode()
    
    def decrypt_key(self, encrypted_key: str) -> str:
        """
        API Key ë³µí˜¸í™”
        """
        decrypted = self.cipher.decrypt(encrypted_key.encode())
        return decrypted.decode()
    
    def rotate_key(self, old_key: str) -> str:
        """
        Key Rotation êµ¬í˜„
        """
        # ê¸°ì¡´ í‚¤ë¡œ ì•”í˜¸í™”ëœ ë°ì´í„° ë³µí˜¸í™”
        decrypted = self.decrypt_key(old_key)
        
        # ìƒˆë¡œìš´ í‚¤ë¡œ ì¬ì•”í˜¸í™”
        new_encrypted = self.encrypt_key(decrypted)
        
        return new_encrypted
-- Supabaseì— ì•”í˜¸í™”ëœ í‚¤ ì €ì¥
CREATE TABLE user_api_keys (
    id uuid PRIMARY KEY DEFAULT uuid_generate_v4(),
    user_id uuid REFERENCES auth.users NOT NULL,
    provider text NOT NULL, -- 'openai', 'anthropic', etc.
    encrypted_key text NOT NULL,
    created_at timestamp DEFAULT now(),
    last_used_at timestamp,
    is_active boolean DEFAULT true,
    
    UNIQUE(user_id, provider)
);

-- Row Level Security ì„¤ì •
ALTER TABLE user_api_keys ENABLE ROW LEVEL SECURITY;

CREATE POLICY "Users can only access their own keys"
    ON user_api_keys
    FOR ALL
    USING (auth.uid() = user_id);
3. íŒŒì¼ ì—…ë¡œë“œ ë³´ì•ˆ
# infrastructure/security/file_validator.py

import magic
import hashlib
from pathlib import Path
from typing import List, Optional
import subprocess

class SecureFileValidator:
    """
    íŒŒì¼ ì—…ë¡œë“œ ë³´ì•ˆ ê²€ì¦
    """
    
    ALLOWED_MIME_TYPES = {
        'application/pdf',
        'text/plain',
        'application/msword',
        'application/vnd.openxmlformats-officedocument.wordprocessingml.document',
        'image/jpeg',
        'image/png',
        'image/webp'
    }
    
    MAX_FILE_SIZE = 10 * 1024 * 1024  # 10MB
    
    def __init__(self):
        self.magic = magic.Magic(mime=True)
    
    async def validate_file(self, file_path: Path) -> dict:
        """
        íŒŒì¼ ê²€ì¦ (íŒŒì¼ ì‹œê·¸ë‹ˆì²˜, í¬ê¸°, ì•…ì„±ì½”ë“œ)
        """
        validation_result = {
            'valid': True,
            'errors': []
        }
        
        # 1. íŒŒì¼ í¬ê¸° ê²€ì¦
        file_size = file_path.stat().st_size
        if file_size > self.MAX_FILE_SIZE:
            validation_result['valid'] = False
            validation_result['errors'].append('File size exceeds limit')
            return validation_result
        
        # 2. MIME íƒ€ì… ê²€ì¦ (íŒŒì¼ ì‹œê·¸ë‹ˆì²˜ ê¸°ë°˜)
        mime_type = self.magic.from_file(str(file_path))
        if mime_type not in self.ALLOWED_MIME_TYPES:
            validation_result['valid'] = False
            validation_result['errors'].append(f'Invalid file type: {mime_type}')
            return validation_result
        
        # 3. íŒŒì¼ í•´ì‹œ ê³„ì‚° (ì¤‘ë³µ ì²´í¬ ë° ë¬´ê²°ì„±)
        file_hash = await self._calculate_hash(file_path)
        validation_result['hash'] = file_hash
        
        # 4. ì•…ì„±ì½”ë“œ ìŠ¤ìº” (ClamAV)
        is_safe = await self._scan_virus(file_path)
        if not is_safe:
            validation_result['valid'] = False
            validation_result['errors'].append('Malware detected')
            return validation_result
        
        # 5. ë©”íƒ€ë°ì´í„° Sanitization
        await self._sanitize_metadata(file_path)
        
        return validation_result
    
    async def _calculate_hash(self, file_path: Path) -> str:
        """
        SHA-256 í•´ì‹œ ê³„ì‚°
        """
        sha256_hash = hashlib.sha256()
        with open(file_path, "rb") as f:
            for byte_block in iter(lambda: f.read(4096), b""):
                sha256_hash.update(byte_block)
        return sha256_hash.hexdigest()
    
    async def _scan_virus(self, file_path: Path) -> bool:
        """
        ClamAVë¡œ ë°”ì´ëŸ¬ìŠ¤ ìŠ¤ìº”
        """
        try:
            result = subprocess.run(
                ['clamscan', '--no-summary', str(file_path)],
                capture_output=True,
                text=True,
                timeout=30
            )
            return 'OK' in result.stdout
        except Exception as e:
            # ClamAVê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì€ ê²½ìš° ë¡œê·¸ë§Œ ë‚¨ê¸°ê³  í†µê³¼
            print(f"Virus scan failed: {e}")
            return True
    
    async def _sanitize_metadata(self, file_path: Path):
        """
        ë¯¼ê°í•œ ë©”íƒ€ë°ì´í„° ì œê±° (exiftool ì‚¬ìš©)
        """
        try:
            subprocess.run(
                ['exiftool', '-all=', '-overwrite_original', str(file_path)],
                capture_output=True,
                timeout=10
            )
        except Exception as e:
            print(f"Metadata sanitization failed: {e}")
4. SQL Injection ë°©ì§€
# infrastructure/database/repositories/document_repository.py

from sqlalchemy import text
from sqlalchemy.ext.asyncio import AsyncSession

class DocumentRepository:
    """
    ì•ˆì „í•œ ë°ì´í„°ë² ì´ìŠ¤ ì¿¼ë¦¬
    """
    
    def __init__(self, session: AsyncSession):
        self.session = session
    
    async def search_documents(
        self,
        user_id: str,
        query: str,
        limit: int = 10
    ) -> List[dict]:
        """
        Parameterized queryë¡œ SQL Injection ë°©ì§€
        """
        # âŒ ì•ˆì „í•˜ì§€ ì•Šì€ ë°©ë²•
        # sql = f"SELECT * FROM documents WHERE user_id = '{user_id}'"
        
        # âœ… ì•ˆì „í•œ ë°©ë²•: Parameterized query
        sql = text("""
            SELECT * FROM documents
            WHERE user_id = :user_id
            AND content LIKE :query
            LIMIT :limit
        """)
        
        result = await self.session.execute(
            sql,
            {
                'user_id': user_id,
                'query': f'%{query}%',
                'limit': limit
            }
        )
        
        return result.fetchall()
5. CORS ë° ë³´ì•ˆ í—¤ë”
# main.py

from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from fastapi.middleware.trustedhost import TrustedHostMiddleware
from starlette.middleware.sessions import SessionMiddleware

app = FastAPI()

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "https://yourdomain.com",
        "https://www.yourdomain.com"
    ],
    allow_credentials=True,
    allow_methods=["GET", "POST", "PUT", "DELETE"],
    allow_headers=["*"],
    max_age=3600
)

# Trusted Host ì„¤ì •
app.add_middleware(
    TrustedHostMiddleware,
    allowed_hosts=["yourdomain.com", "*.yourdomain.com"]
)

# ì„¸ì…˜ ë³´ì•ˆ
app.add_middleware(
    SessionMiddleware,
    secret_key=os.getenv("SESSION_SECRET"),
    https_only=True,
    same_site="strict"
)

# ë³´ì•ˆ í—¤ë” ì¶”ê°€
@app.middleware("http")
async def add_security_headers(request, call_next):
    response = await call_next(request)
    response.headers["X-Content-Type-Options"] = "nosniff"
    response.headers["X-Frame-Options"] = "DENY"
    response.headers["X-XSS-Protection"] = "1; mode=block"
    response.headers["Strict-Transport-Security"] = "max-age=31536000; includeSubDomains"
    response.headers["Content-Security-Policy"] = "default-src 'self'"
    return response
6. ë°ì´í„° í”„ë¼ì´ë²„ì‹œ (GDPR ì¤€ìˆ˜)
# application/use_cases/gdpr_compliance.py

from typing import List
import re

class GDPRComplianceService:
    """
    ê°œì¸ì •ë³´ ë³´í˜¸ ì„œë¹„ìŠ¤
    """
    
    # PII íŒ¨í„´
    PII_PATTERNS = {
        'email': r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b',
        'phone': r'\b\d{3}[-.]?\d{3}[-.]?\d{4}\b',
        'ssn': r'\b\d{3}-\d{2}-\d{4}\b',
        'credit_card': r'\b\d{4}[- ]?\d{4}[- ]?\d{4}[- ]?\d{4}\b'
    }
    
    async def detect_pii(self, text: str) -> List[dict]:
        """
        PII ë°ì´í„° ìë™ ê°ì§€
        """
        detected = []
        
        for pii_type, pattern in self.PII_PATTERNS.items():
            matches = re.finditer(pattern, text)
            for match in matches:
                detected.append({
                    'type': pii_type,
                    'value': match.group(),
                    'start': match.start(),
                    'end': match.end()
                })
        
        return detected
    
    async def mask_pii(self, text: str) -> str:
        """
        PII ë°ì´í„° ë§ˆìŠ¤í‚¹
        """
        masked_text = text
        
        for pii_type, pattern in self.PII_PATTERNS.items():
            if pii_type == 'email':
                masked_text = re.sub(
                    pattern,
                    lambda m: m.group().split('@')[0][:2] + '***@' + m.group().split('@')[1],
                    masked_text
                )
            elif pii_type == 'phone':
                masked_text = re.sub(pattern, '***-***-****', masked_text)
            else:
                masked_text = re.sub(pattern, '***', masked_text)
        
        return masked_text
    
    async def delete_user_data(self, user_id: str):
        """
        ì‚¬ìš©ì ë°ì´í„° ì™„ì „ ì‚­ì œ (GDPR Right to be Forgotten)
        """
        # 1. ë¬¸ì„œ ì‚­ì œ
        await self.document_repo.delete_by_user(user_id)
        
        # 2. ì±„íŒ… ê¸°ë¡ ì‚­ì œ
        await self.chat_repo.delete_by_user(user_id)
        
        # 3. API í‚¤ ì‚­ì œ
        await self.key_repo.delete_by_user(user_id)
        
        # 4. ê°ì‚¬ ë¡œê·¸ ìµëª…í™”
        await self.audit_repo.anonymize_user(user_id)
        
        return {'status': 'deleted', 'user_id': user_id}
    
    async def export_user_data(self, user_id: str) -> dict:
        """
        ì‚¬ìš©ì ë°ì´í„° ë‚´ë³´ë‚´ê¸° (GDPR Right to Data Portability)
        """
        documents = await self.document_repo.get_by_user(user_id)
        chats = await self.chat_repo.get_by_user(user_id)
        
        return {
            'user_id': user_id,
            'documents': documents,
            'chats': chats,
            'exported_at': datetime.now().isoformat()
        }
-- ê°ì‚¬ ë¡œê·¸ í…Œì´ë¸”
CREATE TABLE audit_logs (
    id uuid PRIMARY KEY DEFAULT uuid_generate_v4(),
    user_id uuid REFERENCES auth.users,
    action text NOT NULL,
    resource_type text NOT NULL,
    resource_id text,
    ip_address inet,
    user_agent text,
    created_at timestamp DEFAULT now(),
    
    -- ì¸ë±ìŠ¤
    INDEX idx_audit_user (user_id, created_at DESC),
    INDEX idx_audit_action (action, created_at DESC)
);

-- ë°ì´í„° ë³´ê´€ ì •ì±… (90ì¼ í›„ ìë™ ì‚­ì œ)
CREATE OR REPLACE FUNCTION cleanup_old_audit_logs()
RETURNS void AS $$
BEGIN
    DELETE FROM audit_logs
    WHERE created_at < NOW() - INTERVAL '90 days';
END;
$$ LANGUAGE plpgsql;

SELECT cron.schedule('cleanup-audit-logs', '0 3 * * *',
    'SELECT cleanup_old_audit_logs()');
3. ì¢…í•© ì œì•ˆì„œ
ğŸ¯ ìš°ì„ ìˆœìœ„ë³„ êµ¬í˜„ ê³„íš
Phase 1: ê¸°ë°˜ êµ¬ì¶• ë° ë³´ì•ˆ ê°•í™” (Week 1-2)
ì¦‰ì‹œ ì ìš© í•­ëª©:
ë³´ì•ˆ ê¸°ë³¸ ì„¤ì •
[ ] í™˜ê²½ë³€ìˆ˜ ì•”í˜¸í™” (KeyManager êµ¬í˜„)
[ ] CORS ì •ì±… ë° ë³´ì•ˆ í—¤ë” ì„¤ì •
[ ] íŒŒì¼ ì—…ë¡œë“œ ê²€ì¦ (SecureFileValidator)
[ ] Supabase Auth í†µí•© ë° RBAC êµ¬í˜„
ëª¨ë‹ˆí„°ë§ ê¸°ì´ˆ
[ ] Health check endpoint (/health)
[ ] Sentry í†µí•© (ì—ëŸ¬ íŠ¸ë˜í‚¹)
[ ] ë¡œê¹… ì²´ê³„ êµ¬ì¶• (structlog)
[ ] Audit Log í…Œì´ë¸” ìƒì„±
Database ìµœì í™”
[ ] HNSW ì¸ë±ìŠ¤ ì¶”ê°€
[ ] ë©”íƒ€ë°ì´í„° GIN ì¸ë±ìŠ¤
[ ] Hybrid Search í•¨ìˆ˜ êµ¬í˜„
ê²€ì¦ ê¸°ì¤€:
ëª¨ë“  ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ í†µê³¼
ë³´ì•ˆ ì·¨ì•½ì  ìŠ¤ìº” í†µê³¼
Health check ì •ìƒ ì‘ë‹µ
Phase 2: í•µì‹¬ ê¸°ëŠ¥ êµ¬í˜„ (Week 3-5)
ì£¼ìš” êµ¬í˜„ í•­ëª©:
Hybrid Search ì‹œìŠ¤í…œ
[ ] BM25 í’€í…ìŠ¤íŠ¸ ê²€ìƒ‰ êµ¬í˜„
[ ] Vector Search í†µí•©
[ ] Reranking íŒŒì´í”„ë¼ì¸ (Cohere API)
[ ] ê²€ìƒ‰ ê²°ê³¼ ìœµí•© ì•Œê³ ë¦¬ì¦˜
ìºì‹± ë ˆì´ì–´
[ ] Redis í†µí•© (Upstash ë¬´ë£Œ í‹°ì–´)
[ ] ì¿¼ë¦¬ ì„ë² ë”© ìºì‹±
[ ] LLM ì‘ë‹µ ìºì‹±
[ ] TTL ê¸°ë°˜ ë¬´íš¨í™” ì „ëµ
ë¹„ë™ê¸° ì‘ì—… í
[ ] Celery + Redis ì„¤ì •
[ ] ë¬¸ì„œ ì²˜ë¦¬ ë°±ê·¸ë¼ìš´ë“œ ì‘ì—…
[ ] ì§„í–‰ë¥  ì¶”ì  (Server-Sent Events)
[ ] ì‘ì—… ì‹¤íŒ¨ ì‹œ ì¬ì‹œë„ ë¡œì§
Frontend ê¸°ë³¸ ê¸°ëŠ¥
[ ] íŒŒì¼ ì—…ë¡œë“œ UI (DragDropZone)
[ ] ì±„íŒ… ì¸í„°í˜ì´ìŠ¤
[ ] ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ
[ ] ì†ŒìŠ¤ í‘œì‹œ (SourceCard)
ê²€ì¦ ê¸°ì¤€:
ê²€ìƒ‰ ì •í™•ë„ > 80% (í‰ê°€ ë°ì´í„°ì…‹ ê¸°ì¤€)
ì‘ë‹µ ì‹œê°„ < 2ì´ˆ (ìºì‹œ ë¯¸ì ì¤‘)
ë™ì‹œ ì‚¬ìš©ì 50ëª… ì²˜ë¦¬ ê°€ëŠ¥
Phase 3: ê³ ê¸‰ ê¸°ëŠ¥ ë° ìµœì í™” (Week 6-8)
ê³ ê¸‰ ê¸°ëŠ¥:
ë©€í‹°ëª¨ë‹¬ ì²˜ë¦¬ ê°•í™”
[ ] Vision LM í†µí•© (GPT-4V)
[ ] Audio ì²˜ë¦¬ (Whisper API)
[ ] Table íŒŒì‹± (Unstructured.io)
[ ] ì´ë¯¸ì§€ ë‚´ í…ìŠ¤íŠ¸ OCR
Advanced RAG
[ ] Multi-query generation
[ ] Self-query retrieval
[ ] Hypothetical document embedding
[ ] Query decomposition
ì‚¬ìš©ì ê²½í—˜ í–¥ìƒ
[ ] ëŒ€í™” íˆìŠ¤í† ë¦¬ ê´€ë¦¬
[ ] ë¶ë§ˆí¬ ë° ì¦ê²¨ì°¾ê¸°
[ ] ë¬¸ì„œ íƒœê¹… ì‹œìŠ¤í…œ
[ ] í˜‘ì—… ê¸°ëŠ¥ (ë¬¸ì„œ ê³µìœ )
ì„±ëŠ¥ ìµœì í™”
[ ] Database ì¿¼ë¦¬ ìµœì í™”
[ ] í”„ë¡ íŠ¸ì—”ë“œ ë²ˆë“¤ í¬ê¸° ê°ì†Œ
[ ] Lazy loading êµ¬í˜„
[ ] CDN ì„¤ì • (Cloudflare)
ê²€ì¦ ê¸°ì¤€:
ë©€í‹°ëª¨ë‹¬ ì •í™•ë„ > 75%
í˜ì´ì§€ ë¡œë“œ ì‹œê°„ < 1ì´ˆ
Lighthouse ì ìˆ˜ > 90
Phase 4: í”„ë¡œë•ì…˜ ì¤€ë¹„ (Week 9-10)
ë°°í¬ ë° ìš´ì˜:
CI/CD íŒŒì´í”„ë¼ì¸
[ ] GitHub Actions ì›Œí¬í”Œë¡œìš°
[ ] ìë™ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
[ ] Blue-Green ë°°í¬
[ ] ìë™ ë¡¤ë°±
ëª¨ë‹ˆí„°ë§ ë° ì•Œë¦¼
[ ] Grafana ëŒ€ì‹œë³´ë“œ êµ¬ì„±
[ ] Uptime Robot ì„¤ì •
[ ] Slack ì•Œë¦¼ í†µí•©
[ ] ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
ë°±ì—… ë° ë³µêµ¬
[ ] ìë™ ë°±ì—… ìŠ¤í¬ë¦½íŠ¸
[ ] Backblaze B2 í†µí•©
[ ] ë³µêµ¬ ì ˆì°¨ ë¬¸ì„œí™”
[ ] ì¬í•´ ë³µêµ¬ í…ŒìŠ¤íŠ¸
ë¬¸ì„œí™”
[ ] API ë¬¸ì„œ (OpenAPI/Swagger)
[ ] ì‚¬ìš©ì ê°€ì´ë“œ
[ ] ìš´ì˜ ë§¤ë‰´ì–¼
[ ] ì•„í‚¤í…ì²˜ ë‹¤ì´ì–´ê·¸ë¨
ê²€ì¦ ê¸°ì¤€:
ê°€ë™ë¥  > 99.5%
í‰ê·  ë°°í¬ ì‹œê°„ < 10ë¶„
ë°±ì—… ë³µêµ¬ ì‹œê°„ < 1ì‹œê°„
ğŸ“Š ì˜ˆìƒ ë¦¬ì†ŒìŠ¤ ë° ë¹„ìš©
í•­ëª©
ì„œë¹„ìŠ¤
ë¬´ë£Œ í‹°ì–´ í•œë„
ë¹„ê³ 
Database
Supabase
500MB, 2GB transfer/month
ì¶©ë¶„
Backend
Render
750 hours/month
1ê°œ ì¸ìŠ¤í„´ìŠ¤
Frontend
Vercel
100GB bandwidth
ì¶©ë¶„
Cache
Upstash Redis
10K commands/day
ì¶©ë¶„
Storage
Supabase Storage
1GB
ë¬¸ì„œ ì €ì¥ìš©
Monitoring
Sentry
5K errors/month
ì¶©ë¶„
Backup
Backblaze B2
10GB
ë°±ì—…ìš©
ì´ ë¹„ìš©
$0/month

LLM APIëŠ” ì‚¬ìš©ì ë¶€ë‹´
ğŸ”§ ê¸°ìˆ  ìŠ¤íƒ ìµœì¢… ì •ë¦¬
Backend Stack
Python 3.11+
â”œâ”€â”€ FastAPI (Web Framework)
â”œâ”€â”€ SQLAlchemy (ORM)
â”œâ”€â”€ Celery (Task Queue)
â”œâ”€â”€ Redis (Cache & Queue)
â”œâ”€â”€ LangChain (LLM Integration)
â”œâ”€â”€ Supabase Client (Database)
â””â”€â”€ pytest (Testing)
Frontend Stack
Next.js 14+
â”œâ”€â”€ React 18
â”œâ”€â”€ TypeScript
â”œâ”€â”€ Tailwind CSS
â”œâ”€â”€ Zustand (State Management)
â”œâ”€â”€ React Query (Server State)
â”œâ”€â”€ Socket.io (Real-time)
â””â”€â”€ Vitest (Testing)
Infrastructure Stack
Docker
â”œâ”€â”€ Render (Backend Hosting)
â”œâ”€â”€ Vercel (Frontend Hosting)
â”œâ”€â”€ Supabase (Database + Auth)
â”œâ”€â”€ Upstash (Redis)
â”œâ”€â”€ GitHub Actions (CI/CD)
â””â”€â”€ Sentry (Monitoring)
4. ì•¡ì…˜ ì•„ì´í…œ
ğŸ“ ê° íŒ€ì›ë³„ í• ë‹¹ ì‘ì—…
System Architect
[ ] Architecture Decision Records (ADR) ì‘ì„±
[ ] ì´ë²¤íŠ¸ ê¸°ë°˜ ì•„í‚¤í…ì²˜ ìƒì„¸ ì„¤ê³„
[ ] CQRS êµ¬í˜„ ê°€ì´ë“œ ì‘ì„±
[ ] ì‹œìŠ¤í…œ ë‹¤ì´ì–´ê·¸ë¨ ì‘ì„± (C4 Model)
Backend Engineer
[ ] API ëª…ì„¸ì„œ ì‘ì„± (OpenAPI 3.0)
[ ] Rate Limiting êµ¬í˜„
[ ] Celery ì‘ì—… í ì„¤ì •
[ ] Health Check ì—”ë“œí¬ì¸íŠ¸ êµ¬í˜„
Database Engineer
[ ] ìŠ¤í‚¤ë§ˆ ë§ˆì´ê·¸ë ˆì´ì…˜ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±
[ ] ì¸ë±ì‹± ì „ëµ êµ¬í˜„
[ ] Hybrid Search í•¨ìˆ˜ ìµœì í™”
[ ] ë°ì´í„° ì•„ì¹´ì´ë¹™ ì •ì±… êµ¬í˜„
AI/ML Engineer
[ ] Embedding ì „ëµ êµ¬í˜„ ë° ë²¤ì¹˜ë§ˆí¬
[ ] Reranking íŒŒì´í”„ë¼ì¸ êµ¬ì¶•
[ ] Prompt í…œí”Œë¦¿ ë¼ì´ë¸ŒëŸ¬ë¦¬ êµ¬ì¶•
[ ] ë©€í‹°ëª¨ë‹¬ í”„ë¡œì„¸ì„œ êµ¬í˜„
DevOps Engineer
[ ] Docker ì´ë¯¸ì§€ ìµœì í™”
[ ] CI/CD íŒŒì´í”„ë¼ì¸ êµ¬ì¶•
[ ] ëª¨ë‹ˆí„°ë§ ìŠ¤íƒ ì„¤ì •
[ ] ë°±ì—… ìë™í™” ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±
Frontend Engineer
[ ] ì»´í¬ë„ŒíŠ¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ êµ¬ì¶•
[ ] ìŠ¤íŠ¸ë¦¬ë° ì±„íŒ… UI êµ¬í˜„
[ ] íŒŒì¼ ì—…ë¡œë“œ UX ê°œì„ 
[ ] ì ‘ê·¼ì„± í…ŒìŠ¤íŠ¸ ë° ê°œì„ 
Security Engineer
[ ] ë³´ì•ˆ ì²´í¬ë¦¬ìŠ¤íŠ¸ ì‘ì„±
[ ] ì¸ì¦/ì¸ê°€ ì‹œìŠ¤í…œ êµ¬í˜„
[ ] íŒŒì¼ ê²€ì¦ ë¡œì§ êµ¬í˜„
[ ] GDPR ì»´í”Œë¼ì´ì–¸ìŠ¤ ê°€ì´ë“œ ì‘ì„±
ğŸ“… ì£¼ì°¨ë³„ ë§ˆì¼ìŠ¤í†¤
Week 1-2: Foundation
âœ… ë³´ì•ˆ ê¸°ë°˜ êµ¬ì¶•
âœ… DB ìŠ¤í‚¤ë§ˆ ìµœì í™”
âœ… ëª¨ë‹ˆí„°ë§ ì„¤ì •
Week 3-4: Core Features
âœ… Hybrid Search êµ¬í˜„
âœ… ìºì‹± ì‹œìŠ¤í…œ
âœ… ê¸°ë³¸ UI êµ¬ì¶•
Week 5-6: Advanced Features
âœ… ë©€í‹°ëª¨ë‹¬ ì²˜ë¦¬
âœ… Advanced RAG
âœ… ë¹„ë™ê¸° ì‘ì—… í
Week 7-8: Optimization
âœ… ì„±ëŠ¥ íŠœë‹
âœ… UX ê°œì„ 
âœ… ë¶€í•˜ í…ŒìŠ¤íŠ¸
Week 9-10: Production
âœ… CI/CD êµ¬ì¶•
âœ… ë¬¸ì„œí™” ì™„ë£Œ
âœ… í”„ë¡œë•ì…˜ ë°°í¬
5. ìœ„í—˜ ìš”ì†Œ ë° ëŒ€ì‘ ë°©ì•ˆ
ğŸš¨ ì£¼ìš” ë¦¬ìŠ¤í¬
ìœ„í—˜
ì˜í–¥ë„
ë°œìƒ ê°€ëŠ¥ì„±
ëŒ€ì‘ ë°©ì•ˆ
ë¬´ë£Œ í‹°ì–´ í•œë„ ì´ˆê³¼
ë†’ìŒ
ì¤‘ê°„
Rate Limiting, ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§
LLM API ë¹„ìš© ê¸‰ì¦
ë†’ìŒ
ì¤‘ê°„
ìºì‹±, ìš”ì²­ ìµœì í™”
ë³´ì•ˆ ì·¨ì•½ì 
ë§¤ìš° ë†’ìŒ
ë‚®ìŒ
ì •ê¸° ë³´ì•ˆ ê°ì‚¬, ìë™í™”ëœ ìŠ¤ìº”
ì„±ëŠ¥ ì €í•˜
ì¤‘ê°„
ë†’ìŒ
ìºì‹±, ì¸ë±ì‹±, ìµœì í™”
ë°ì´í„° ì†ì‹¤
ë†’ìŒ
ë‚®ìŒ
ìë™ ë°±ì—…, ë³µì œ
ğŸ›¡ï¸ ëŒ€ì‘ ì „ëµ
1. ë¹„ìš© ê´€ë¦¬
# Cost Monitoring Service
class CostMonitor:
    MONTHLY_BUDGET = 100  # USD
    
    async def check_budget(self):
        current_spending = await self.get_current_month_spending()
        
        if current_spending > self.MONTHLY_BUDGET * 0.8:
            # 80% ë„ë‹¬ ì‹œ ì•Œë¦¼
            await self.send_alert("Budget warning: 80% reached")
        
        if current_spending > self.MONTHLY_BUDGET:
            # í•œë„ ì´ˆê³¼ ì‹œ ê¸°ëŠ¥ ì œí•œ
            await self.enable_rate_limiting()
            await self.disable_expensive_features()
2. ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
# Performance Monitoring
from prometheus_client import Histogram

response_time = Histogram(
    'prism_response_time_seconds',
    'Response time',
    buckets=[0.1, 0.5, 1.0, 2.0, 5.0]
)

@app.middleware("http")
async def monitor_performance(request, call_next):
    with response_time.time():
        response = await call_next(request)
    return response
6. ì¶”ê°€ ì œì•ˆ ë¬¸ì„œ ëª©ë¡
ë‹¤ìŒ ë¬¸ì„œë“¤ì„ ë³„ë„ë¡œ ì‘ì„±í•˜ì—¬ í”„ë¡œì íŠ¸ ë ˆí¬ì§€í† ë¦¬ì— ì¶”ê°€í•  ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤:
ğŸ“š í•„ìˆ˜ ë¬¸ì„œ
ADR/ (Architecture Decision Records)
001-database-selection.md
002-llm-abstraction.md
003-authentication-strategy.md
API_SPECS.md
OpenAPI 3.0 ëª…ì„¸
ì—”ë“œí¬ì¸íŠ¸ ìƒì„¸ ì„¤ëª…
ìš”ì²­/ì‘ë‹µ ì˜ˆì‹œ
DATABASE_SCHEMA.md
ERD ë‹¤ì´ì–´ê·¸ë¨
í…Œì´ë¸” ì •ì˜
ì¸ë±ì‹± ì „ëµ
SECURITY_CHECKLIST.md
OWASP Top 10 ì²´í¬ë¦¬ìŠ¤íŠ¸
ë³´ì•ˆ ì„¤ì • ê°€ì´ë“œ
ì·¨ì•½ì  ëŒ€ì‘ ë°©ì•ˆ
TESTING_STRATEGY.md
ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ê°€ì´ë“œ
í†µí•© í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤
E2E í…ŒìŠ¤íŠ¸ ê³„íš
DEPLOYMENT_GUIDE.md
í™˜ê²½ë³„ ë°°í¬ ì ˆì°¨
ë¡¤ë°± í”„ë¡œì„¸ìŠ¤
íŠ¸ëŸ¬ë¸”ìŠˆíŒ… ê°€ì´ë“œ
MONITORING_GUIDE.md
ë©”íŠ¸ë¦­ ì •ì˜
ì•Œë¦¼ ì„¤ì •
ëŒ€ì‹œë³´ë“œ êµ¬ì„±
USER_MANUAL.md
ì‚¬ìš©ì ê°€ì´ë“œ
FAQ
íŠ¸ëŸ¬ë¸”ìŠˆíŒ…
7. íšŒì˜ ê²°ë¡  ë° ë‹¤ìŒ ë‹¨ê³„
âœ… íšŒì˜ ê²°ê³¼ ìš”ì•½
[Senior Developer]:
ëª¨ë“  íŒ€ì›ë¶„ë“¤ì˜ ì˜ê²¬ì„ ì¢…í•©í•œ ê²°ê³¼, PRISM í”„ë¡œì íŠ¸ëŠ” ë‹¤ìŒê³¼ ê°™ì´ ì§„í–‰í•˜ê² ìŠµë‹ˆë‹¤:
ì¦‰ì‹œ ì‹œì‘: Phase 1 ì‘ì—… (ë³´ì•ˆ ê¸°ë°˜ + DB ìµœì í™”)
ì£¼ì°¨ë³„ ìŠ¤í”„ë¦°íŠ¸: 2ì£¼ ë‹¨ìœ„ ìŠ¤í”„ë¦°íŠ¸ë¡œ ì§„í–‰
ì •ê¸° ë¦¬ë·°: ë§¤ì£¼ ê¸ˆìš”ì¼ ì§„í–‰ ìƒí™© ê²€í† 
í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€: ìµœì†Œ 80% ìœ ì§€
ğŸ“‹ Next Actions
ì´ë²ˆ ì£¼ ë‚´ ì™„ë£Œ:
[ ] GitHub Repository ì´ˆê¸°í™”
[ ] Supabase í”„ë¡œì íŠ¸ ìƒì„± ë° ìŠ¤í‚¤ë§ˆ ì ìš©
[ ] Docker ê°œë°œ í™˜ê²½ ì„¤ì •
[ ] CI/CD íŒŒì´í”„ë¼ì¸ ê¸°ë³¸ êµ¬ì¡°
ë‹¤ìŒ ì£¼:
[ ] ë³´ì•ˆ ê¸°ë³¸ ì„¤ì • ì™„ë£Œ
[ ] Health Check êµ¬í˜„
[ ] ì²« ë²ˆì§¸ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‘ì„±
ğŸ¯ ì„±ê³µ ê¸°ì¤€
í”„ë¡œì íŠ¸ ì„±ê³µì„ ë‹¤ìŒê³¼ ê°™ì´ ì •ì˜í•©ë‹ˆë‹¤:
ê¸°ëŠ¥ì  ìš”êµ¬ì‚¬í•­
âœ… ë¬¸ì„œ ì—…ë¡œë“œ ë° ê²€ìƒ‰ ê¸°ëŠ¥
âœ… LLM ê¸°ë°˜ QA ê¸°ëŠ¥
âœ… ë©€í‹°ëª¨ë‹¬ ì§€ì›
ë¹„ê¸°ëŠ¥ì  ìš”êµ¬ì‚¬í•­
âœ… ì‘ë‹µ ì‹œê°„ < 2ì´ˆ
âœ… ê°€ë™ë¥  > 99%
âœ… í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ > 80%
âœ… Zero Cost ìš´ì˜ ë‹¬ì„±
í’ˆì§ˆ ìš”êµ¬ì‚¬í•­
âœ… Clean Architecture ì¤€ìˆ˜
âœ… TDD ì›ì¹™ ì¤€ìˆ˜
âœ… ë³´ì•ˆ ì²´í¬ë¦¬ìŠ¤íŠ¸ 100% ë‹¬ì„±
8. ì°¸ê³  ìë£Œ
ğŸ“– ì¶”ì²œ í•™ìŠµ ìë£Œ
Architecture:
Clean Architecture by Robert C. Martin
Hexagonal Architecture
RAG Systems:
LangChain Documentation
Advanced RAG Techniques
Security:
OWASP Top 10
FastAPI Security
Testing:
pytest Documentation
TDD Best Practices
ë¶€ë¡: ë¹ ë¥¸ ì‹œì‘ ì²´í¬ë¦¬ìŠ¤íŠ¸
âœ… ê°œë°œ í™˜ê²½ ì„¤ì • (30ë¶„)
# 1. Repository í´ë¡ 
git clone https://github.com/your-org/prism.git
cd prism

# 2. Python ê°€ìƒí™˜ê²½ ìƒì„±
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# 3. ì˜ì¡´ì„± ì„¤ì¹˜
pip install -r requirements.txt

# 4. í™˜ê²½ë³€ìˆ˜ ì„¤ì •
cp .env.example .env
# .env íŒŒì¼ì„ í¸ì§‘í•˜ì—¬ API í‚¤ ì…ë ¥

# 5. Supabase ì„¤ì •
# - Supabase ëŒ€ì‹œë³´ë“œì—ì„œ í”„ë¡œì íŠ¸ ìƒì„±
# - SQL Editorì—ì„œ ì´ˆê¸°í™” ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
# - .envì— URLê³¼ API Key ì…ë ¥

# 6. í…ŒìŠ¤íŠ¸ ì‹¤í–‰
pytest tests/

# 7. ê°œë°œ ì„œë²„ ì‹œì‘
uvicorn main:app --reload

# 8. Frontend ì‹œì‘ (ë³„ë„ í„°ë¯¸ë„)
cd frontend
npm install
npm run dev
âœ… ì²« ë²ˆì§¸ ê¸°ëŠ¥ êµ¬í˜„ (TDD)
# 1. ì‹¤íŒ¨í•˜ëŠ” í…ŒìŠ¤íŠ¸ ì‘ì„±
# tests/unit/test_document_upload.py

def test_upload_document():
    # Given
    document = create_test_document()
    
    # When
    result = upload_service.upload(document)
    
    # Then
    assert result.success == True
    assert result.document_id is not None
# 2. ìµœì†Œí•œì˜ êµ¬í˜„
# application/use_cases/upload_document.py

class UploadDocumentUseCase:
    async def execute(self, document):
        # êµ¬í˜„
        pass
# 3. í…ŒìŠ¤íŠ¸ í†µê³¼ê¹Œì§€ ë°˜ë³µ
# 4. ë¦¬íŒ©í† ë§
ë¬¸ì„œ ë²„ì „: 1.0
ìµœì¢… ì—…ë°ì´íŠ¸: 2025-12-11
ë‹¤ìŒ ë¦¬ë·°: 2025-12-18
ë¬¸ì„œ ë
ì´ íšŒì˜ë¡ì€ PRISM í”„ë¡œì íŠ¸ì˜ ê¸°ìˆ ì  ë°©í–¥ì„±ê³¼ êµ¬í˜„ ê³„íšì„ ë‹´ê³  ìˆìŠµë‹ˆë‹¤.
ê° íŒ€ì›ì€ í• ë‹¹ëœ ì•¡ì…˜ ì•„ì´í…œì„ ì§„í–‰í•˜ê³ , ì£¼ê°„ ë¦¬ë·°ì—ì„œ ì§„í–‰ ìƒí™©ì„ ê³µìœ í•´ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.
ì§ˆë¬¸ì´ë‚˜ ì œì•ˆì‚¬í•­ì€ í”„ë¡œì íŠ¸ Slack ì±„ë„ #prism-devì— ë‚¨ê²¨ì£¼ì„¸ìš”.