# RAG 시스템 개선 영향 분석 보고서

> **문서 ID**: 2601061838_RAG_Improvement_Impact_Analysis  
> **작성일**: 2026-01-06 18:38  
> **작성자**: PRISM Writer 기술 팀  
> **목적**: RAG 시스템 8점 도달을 위한 개선 사항이 실제 서비스 엔진과 파이프라인에 미치는 구체적인 영향 분석

---

## 1. 개요 및 결론

이번 개선 작업의 **핵심 대상은 Retrieval Pipeline (검색 파이프라인)**입니다.  
사용자의 질문에 대해 가장 적절한 문서를 찾아내는 **"검색 엔진"의 성능을 직접적으로 향상**시키는 작업입니다.

| 질문                                 | 답변                                                  |
| ------------------------------------ | ----------------------------------------------------- |
| **서비스 엔진이 개선되나요?**        | ✅ **예** (검색 엔진의 핵심 성능 향상)                |
| **Retrieval Pipeline이 개선되나요?** | ✅ **직접적인 개선 대상**                             |
| **Rubric Pipeline이 개선되나요?**    | ⚪ 간접적 개선 (더 질 좋은 데이터를 입력받게 됨)      |
| **사용자 체감 효과는?**              | 검색 결과의 정확도 향상, 원하는 문서를 더 빠르게 찾음 |

---

## 2. 시스템 개선 구조도

아래 다이어그램은 현재 PRISM Writer 시스템의 전체 구조와 이번 작업으로 개선되는 영역을 보여줍니다.

```
┌─────────────────────────────────────────────────────────────────────┐
│                    PRISM Writer 시스템 전체 구조                      │
├─────────────────────────────────────────────────────────────────────┤
│                                                                     │
│  [사용자 질문] ──▶ [Retrieval Pipeline] ──▶ [Rubric Pipeline]        │
│                        ⬆️ 개선 대상                                  │
│                                                                     │
│  ┌──────────────────────────────────────────────────────────────┐   │
│  │                  Retrieval Pipeline                          │   │
│  │  ┌─────────┐  ┌─────────────┐  ┌──────────┐  ┌──────────┐   │   │
│  │  │ Vector  │  │   Keyword   │  │  Hybrid  │  │ Re-rank  │   │   │
│  │  │ Search  │──│   Search    │──│  Fusion  │──│   LLM    │   │   │
│  │  │(pgvector)│ │(ts_rank)    │  │(RRF/WSF) │  │          │   │   │
│  │  └────┬────┘  └──────┬──────┘  └────┬─────┘  └────┬─────┘   │   │
│  │       │              │              │              │        │   │
│  │       ▼              ▼              ▼              ▼        │   │
│  │   ⚠️ 한글      ⚠️ 정확도       ✅ 구현됨    ⚠️ LLM 비용    │   │
│  │   형태소 미지원   측정 없음                    효율성        │   │
│  │                                                              │   │
│  │  [🔧 개선 영역]                                              │   │
│  │  1. Cross-Encoder ──▶ Re-rank 정확도 향상                   │   │
│  │  2. 한글 형태소 ──▶ Keyword Search 정확도 향상              │   │
│  │  3. MRR/NDCG 측정 ──▶ 전체 품질 모니터링                    │   │
│  └──────────────────────────────────────────────────────────────┘   │
│                                                                     │
│                              ▼                                      │
│                                                                     │
│  ┌──────────────────────────────────────────────────────────────┐   │
│  │                   Rubric Pipeline (변경 없음)                 │   │
│  │  [Rule Miner] ──▶ [Pattern Extractor] ──▶ [Template Builder] │   │
│  └──────────────────────────────────────────────────────────────┘   │
│                                                                     │
└─────────────────────────────────────────────────────────────────────┘
```

---

## 3. 세부 개선 항목과 영향

각 개선 항목이 어떤 파이프라인의 어떤 기능을 강화하는지 상세 분석했습니다.

| 개선 항목                              | 영향 파이프라인 | 영향 받는 기능             | 실제 효과                                                                     |
| -------------------------------------- | --------------- | -------------------------- | ----------------------------------------------------------------------------- |
| **Cross-Encoder 적용**<br>(BGE/Cohere) | Retrieval       | `rerankResults()`          | **재정렬 정확도 향상**<br>LLM보다 빠르고 정확하게 상위 문서를 선별함          |
| **한글 형태소 분석**<br>(n-gram/API)   | Retrieval       | `fullTextSearchWithRank()` | **키워드 검색 재현율 향상**<br>"문장력" 검색 시 "문장"이 포함된 문서도 찾아냄 |
| **정량 평가 체계**<br>(MRR/NDCG)       | Retrieval       | 품질 모니터링              | **객관적 성능 지표 확보**<br>개선 전후를 숫자로 비교하여 지속적 튜닝 가능     |
| **Ground Truth 구축**                  | Retrieval       | 품질 기준선                | **검색 품질의 정답지 확보**<br>무엇이 "좋은 검색"인지 시스템에 정의           |

---

## 4. Before vs After 비교 시나리오

개선 적용 전후 시나리오를 통해 변화를 구체적으로 확인할 수 있습니다.

### 4.1. Cross-Encoder 개선 (Re-ranking)

> **상황**: 사용자가 "후킹 기법 예시"를 검색했을 때

**Before (현재 LLM Re-ranking)**:

- **프로세스**: 검색 결과 20개를 LLM에게 보내서 순서를 정해달라고 요청.
- **문제점**:
  - **비용**: 검색 1회당 약 500 토큰 소모 (비용 발생).
  - **속도**: LLM 응답 대기로 인해 2~3초 지연.
  - **정확도**: LLM의 변덕에 따라 순서가 바뀔 수 있음.
- **결과**: 관련 문서를 찾긴 하지만 느리고 비용이 듦.

**After (Cross-Encoder 도입)**:

- **프로세스**: 검색 결과 20개를 전문 랭킹 모델(Cross-Encoder)이 직접 점수 계산.
- **개선점**:
  - **비용**: 무료(BGE) 또는 매우 저렴($0.001/요청, Cohere).
  - **속도**: 0.5~1초 이내로 단축.
  - **정확도**: 랭킹 전용으로 학습된 모델이라 훨씬 일관되고 정확함.
- **결과**: "후킹 기법"에 딱 맞는 예시가 1위에 즉시 표시됨.

---

### 4.2. 한글 형태소 분석 개선 (Keyword Search)

> **상황**: 사용자가 "문장력 향상 방법"을 검색했을 때

**Before (현재 Simple 토큰화)**:

- **토큰**: `["문장력", "향상", "방법"]` (공백 기준 분리)
- **문제점**: 문서에 "문장 작성 팁"이라는 말이 있어도, "문장력"과 "문장"은 다른 글자로 인식되어 매칭되지 않음.
- **결과**: 관련 문서를 놓침 (Recall 저하).

**After (형태소 분석/n-gram 적용)**:

- **토큰**: `["문장", "력", "문장력", "향상", "방법"]` (의미 단위 분해)
- **개선점**: "문장"이라는 단어가 포함된 모든 문서를 후보로 가져올 수 있음.
- **결과**: 사용자가 의도한 문서를 빠짐없이 찾아냄 (Recall 향상).

---

## 5. Rubric Pipeline은 왜 그대로인가요?

**Rubric Pipeline**(규칙, 예시, 패턴 추출 엔진)은 현재 **7.0/10점**으로 비교적 완성도가 높습니다.

- **역할 분담**: Rubric Pipeline은 "주어진 문서"에서 정보를 추출하는 역할입니다.
- **문제의 본질**: 현재 시스템의 병목은 "어떤 문서를 줄 것인가"(Retrieval)에 있습니다.
- **간접 효과**: Retrieval Pipeline이 개선되어 더 관련성 높은 문서를 Rubric Pipeline에 넘겨주면, 결과적으로 **추출되는 규칙과 패턴의 품질도 함께 좋아집니다.**

> "좋은 재료(Retrieval)가 있어야 맛있는 요리(Rubric)가 나옵니다."

---

## 요약

이번 개선 작업은 **우리 서비스의 검색 엔진(Retrieval Pipeline)을 대기업 수준으로 업그레이드**하는 과정입니다.

1. **더 똑똑하게 찾고** (형태소 분석)
2. **더 정확하게 줄 세워서** (Cross-Encoder)
3. **그 성능을 숫자로 증명** (MRR/NDCG)

하는 것이 목표이며, 이는 사용자에게 **"원하는 걸 바로 찾아주는 똑똑한 AI"**라는 경험을 제공하게 됩니다.
