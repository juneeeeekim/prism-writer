# RAG 시스템 업그레이드 설계 회의록

핵심을 우리 RAG(부합도 평가 + 업그레이드 코칭) 시스템에 옮기면 한 문장으로 이거예요:

> "사용자가 주도하고, AI는 빠르게 '안전한 제안'을 만들고, 적용은 항상 사용자가 승인(원클릭)한다."
> (+ 제안은 내 글/내 기준을 망치지 않는 선에서만)

아래 회의 참석자 전원 초대했고, "Cursor식 Human-in-the-loop + Shadow Workspace"를 우리 파이프라인에 적용하는 개발 방향을 각자 아이디어로 제출합니다.

---

## 👥 회의 참석자 소개(이번 주제용)

- 시니어 개발자(사회)
- IR/검색 엔지니어(BM25)
- LLM/RAG 아키텍트
- 프롬프트/컨텍스트 엔지니어
- UX/프론트엔드 리드
- Eval/QA 리드
- SRE/MLOps
- Security/Privacy
- PM(제품)

---

## 1) 시니어 개발자(사회): 개발 방향(아키텍처 한 장)

**핵심 컨셉을 제품 기능으로 번역**

- Human-in-the-loop = "승인 전까지는 절대 본문을 바꾸지 않기"
- `Tab`(원클릭 적용) = "Apply patch"
- Shadow Workspace = "별도 작업공간에서 수정안/점수변화 미리보기"

**파이프라인(사용자 글 1회 실행)**

1. 사용자 글 입력
2. BM25로 기준/규칙/예시(찾기) 회수
3. (없으면) LLM이 예시 생성 + 판정 템플릿 생성(오프라인/배치 권장)
4. 현재 글을 템플릿으로 평가 → Gap Top3
5. 개선안 생성은 **"Patch 단위"** 로 생성 (문장 추가/교체/이동)
6. Shadow Workspace에서 **적용 후 예상 결과(부합도 변화)** 를 계산
7. 사용자는 `Tab`처럼 `Apply`(1개/전체) 또는 `Reject`

---

## 2) IR/검색 엔지니어(BM25): "문맥 수동 지정(@files) 문제" 해결 방향

이미지에서 "문맥을 수동 지정해야 하는 치명적 단점"이 있었죠. 우리 시스템은 이걸 줄여야 합니다.

**아이디어**

- BM25 인덱스를 2개로 분리
  - Rule Index(규칙/정의/원칙)
  - Example Index(예시/사례/샘플)
- "사용자가 @files로 고르기" 대신
  - 시스템이 **자동으로 '관련 근거 후보 10개'** 를 제시하고
  - 사용자는 **Pin(고정)/Unpin(해제)** 만 하면 되게
- 쿼리는 LLM이 만들되, 흔들리지 않게 고정 템플릿(슬롯) 형태로:
  - `기준그룹 + 사용자 글 문제구간 요약 + 필수 키워드`

---

## 3) LLM/RAG 아키텍트: "AI가 코드(글)를 망치지 않는 선"

Cursor의 승리요인("내 코드를 망치지 않는 선")을 우리에선 이렇게 강제합니다.

**아이디어(가드레일 3종)**

1. **Patch-only 생성**: 완성문 재작성 금지(기본값)
   - `Replace`, `Insert`, `Move`, `Delete` 같은 제한된 편집 명령만
2. **근거 인용 강제**: 모든 조언/패치는 "어떤 규칙 때문에"인지 연결
3. **적용 전 시뮬레이션**: Shadow Workspace에서 점수/프로필 변화를 먼저 보여줌
   - 사용자가 납득한 뒤에만 적용

---

## 4) 프롬프트/컨텍스트 엔지니어: "Shadow Workspace를 구조로 만들기"

**아이디어**

- 결과물은 텍스트가 아니라 **구조화된 'Change Plan'** 으로 반환:
  - `patches[]` (각 패치에: 대상 범위, 변경 전/후, 이유, 근거, 예상효과)
  - `expected_alignment_delta` (축별 변화)
- "Tab 경험"을 위해 UI에는
  - `[Tab=Apply]` `[Shift+Tab=Undo]` 같은 단축키/버튼 제공(웹에서도 가능)

---

## 5) UX/프론트: "사용자가 빠르게 '선택'하게"

**아이디어**

- 화면을 3패널로 구성
  1. 내 글(편집기)
  2. 부합도 프로필(축별 Fit/Gap)
  3. 제안 카드(패치 단위)
- 각 제안 카드는 반드시:
  - 무엇을 바꾸는지(하이라이트)
  - 왜(규칙/근거 링크)
  - 적용하면 뭐가 좋아지는지(예상 변화)
- "속도"는 제안 개수로 내는 게 아니라
  - Top3만 먼저 + "더 보기"로 확장

---

## 6) Eval/QA: "망치지 않는 선"을 자동으로 검증

**아이디어(게이트)**

- **Diff Safety Gate**: 수정량 상한(예: 전체 글의 10~20% 이상 변경이면 경고)
- **Citation Gate**: 근거 인용이 실제 원문에 존재해야 승인 가능
- **Regression Gate**: 같은 글/비슷한 글에서 결과가 과도하게 튀면 경고
- **Upgrade Effect Gate**: 적용 후 부합도 개선이 없으면 "효과 없음" 표시(권장안에서 제외)

---

## 7) SRE/MLOps: "빠르면서도 비용 폭발 방지"

**아이디어**

- Shadow Workspace 계산을 위해 "평가"가 반복되므로:
  - Retrieval/Criteria Pack 캐시
  - Patch 적용 후 재평가는 축별로 부분 평가(가능하면)
- 템플릿 생성/예시 생성은 온라인 실시간이 아니라 배치로(품질/비용/안정성)

---

## 8) Security/Privacy: "승인형 UX가 보안에도 유리"

**아이디어**

- 자동 적용이 없으니 사용자 통제성이 올라가고 사고가 줄어듦
- 다만 "근거/로그"에 사용자 텍스트가 남을 수 있으니:
  - 로그 최소화 + 마스킹 옵션 + 테넌트/ACL 필터는 Retrieval 단계 강제

---

## 9) PM: MVP 개발 방향(이번 변경 반영)

MVP는 이렇게 잡는 게 제일 현실적

- BM25 기반 Rule/Example Retrieval
- Criteria Pack 자동 구성(핀/언핀 UX 포함)
- Alignment 평가 + Gap Top3
- Patch 3개 제안 + Shadow Workspace 미리보기 + Apply/Undo
- 게이트(Citation + Diff Safety)

---

## ✅ 결론: 개발 방향(딱 3줄)

1. AI는 "완성문"이 아니라 **"패치"** 를 제안한다. (망치지 않기)
2. Shadow Workspace에서 적용 후 결과를 미리 보여주고, 사용자가 `Tab`처럼 적용한다. (속도)
3. BM25로 기준/예시를 안정적으로 찾고, 없으면 LLM이 예시/템플릿을 배치로 만든다. (일관성)

---

## 📋 다음 단계

원하면 다음 답변에서 바로 **"Change Plan(JSON 스키마)"** + **"Patch 명령 규격(Replace/Insert/Move/Delete)"** + **"Shadow Workspace 평가 흐름"** 을 문서로 확정해서, 개발이 바로 들어가게 정리해드릴게요.
