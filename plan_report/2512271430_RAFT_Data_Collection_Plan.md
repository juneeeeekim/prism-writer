# RAFT 데이터 수집 전략 아이디어 회의록

**일시**: 2025-12-27 (Phase 4-D 착수 전)
**참석자**: 시니어 개발자, AI 데이터 엔지니어, UX/UI 전문가

---

## 1. 🎯 목표

RAFT(Retrieval Augmented Fine Tuning) 모델 학습을 위한 고품질 데이터셋 500개 자동 구축.

## 2. 🤖 프로세스 상세 (시니어 개발자 제안)

현재 보유한 **RAG 지식청크(`document_chunks`)**를 원천 데이터(Source)로 활용하여, LLM이 스스로 문제를 출제하고 정답을 만드는 **Self-Instruct 방식**을 제안합니다.

### 데이터 흐름 파이프라인

1.  **Source Fetching**: DB의 `document_chunks` 테이블에서 텍스트가 충분히 긴(500자 이상) 청크를 무작위로 추출합니다.
2.  **Generation Request**: 추출된 청크를 `/api/raft/generate` API에 `Context`로 전달합니다.
3.  **LLM Processing**:
    - 역할: "글쓰기 교육 전문가"
    - 지시: "이 내용을 바탕으로 사용자가 물어볼 만한 질문과, 그에 대한 정확한 답변을 만들어라."
4.  **Auto-Save**: 생성된 Q&A 쌍을 `raft_dataset` 테이블에 저장합니다.

## 3. 🕵️ 전문가 검토 및 아이디어

### A. AI 데이터 엔지니어의 의견

> "단순 랜덤 생성은 위험할 수 있습니다. 데이터의 **다양성(Diversity)**과 **무결성(Integrity)**을 확보해야 합니다."

1.  **환각(Hallucination) 필터링 강화**:
    - 생성된 '정답'이 원문 'Context'에 없는 단어를 너무 많이 포함하면 안 됩니다.
    - **제안**: `converter.ts` 단계에서 정답과 문맥의 유사도(Jaccard Similarity 등)를 간단히 체크하거나, 정답에 포함된 주요 키워드가 문맥에 있는지 검사하는 로직을 추가하면 좋습니다.
2.  **오답(Bad Answer) 데이터의 필요성**:

    - RAFT 논문에 따르면, "무엇이 틀린 답인지" 배우는 것도 중요합니다.
    - **제안**: 초기 500개는 정답(Gold Answer) 위주로 가되, 추후 고도화 단계에서 'Context와 무관한 답변'을 일부러 생성해서 `bad_answer` 컬럼에 넣는 스크립트를 별도로 돌리는 전략을 추천합니다. 현재 스키마는 이를 지원(`bad_answer?`)하므로 확장성은 충분합니다.

3.  **비용 효율성**:
    - 500개 생성 시 GPT-4o-mini 기준 약 $0.5 ~ $1.0 예상됩니다. 매우 저렴하므로 비용 걱정보다는 **품질**에 집중해도 됩니다.

### B. UX/UI 전문가의 의견

> "이 과정이 사용자(관리자)에게 어떻게 보여지나요?"

1.  **진행률 시각화**:
    - 스크립트가 백그라운드에서 돌더라도, 관리자 대시보드에서 "현재 350/500개 수집됨" 같은 진행 상황을 볼 수 있어야 합니다.
    - **제안**: `StatCard` 컴포넌트에 'RAFT 데이터 수집 현황' 카드를 추가하여 실시간 카운트를 보여주면 좋겠습니다.

## 4. 📝 최종 구현 계획 (Action Items)

1.  **스크립트 작성 (`scripts/collect_raft_data.ts`)**:

    - `document_chunks` 랜덤 조회 쿼리 구현.
    - 배치 단위(50개씩) 실행 및 딜레이(Rate Limit 방지) 적용.
    - 일일 한도(500개) 도달 시 자동 종료.

2.  **예외 처리**:
    - LLM 응답 실패 시 해당 Chunk는 스킵하고 다음으로 진행 (전체 프로세스 중단 X).

---

**결론**: 위 전략대로 `document_chunks` 기반의 자동 생성을 진행하되, **서버 재시작 후** 실행하여 환경 변수 로드 문제를 해결하고 시작하는 것이 안전합니다.
